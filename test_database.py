#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Vector Database Functionality
Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¸Ø§Ø¦Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©
"""

import sys
import os
import tempfile
import shutil

def test_embeddings():
    """Test embeddings model"""
    print("ğŸ”¤ Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†...")
    
    try:
        from langchain_ollama import OllamaEmbeddings
        
        # Test embeddings initialization
        embeddings = OllamaEmbeddings(model="nomic-embed-text")
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†")
        
        # Test embedding generation
        test_texts = [
            "Hello world",
            "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",
            "Python programming",
            "Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø¨Ù„ØºØ© Python"
        ]
        
        for text in test_texts:
            try:
                embedding = embeddings.embed_query(text)
                print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªØ¶Ù…ÙŠÙ† Ù„Ù„Ù†Øµ: '{text[:20]}...' (Ø§Ù„Ø·ÙˆÙ„: {len(embedding)})")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¶Ù…ÙŠÙ†: {str(e)[:50]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¶Ù…ÙŠÙ†: {e}")
        return False

def test_vector_database():
    """Test vector database operations"""
    print("\nğŸ“š Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©...")
    
    try:
        from langchain_ollama import OllamaEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.documents import Document
        
        # Create temporary directory for test database
        temp_dir = tempfile.mkdtemp()
        
        try:
            # Initialize embeddings and database
            embeddings = OllamaEmbeddings(model="nomic-embed-text")
            vector_db = Chroma(
                persist_directory=temp_dir,
                embedding_function=embeddings
            )
            
            print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©")
            
            # Test documents
            test_documents = [
                Document(page_content="Python is a programming language", metadata={"source": "test1"}),
                Document(page_content="JavaScript is used for web development", metadata={"source": "test2"}),
                Document(page_content="Machine learning is a subset of AI", metadata={"source": "test3"}),
                Document(page_content="Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø¨Ù„ØºØ© Python Ø³Ù‡Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…", metadata={"source": "test4"}),
                Document(page_content="JavaScript ØªØ³ØªØ®Ø¯Ù… Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨", metadata={"source": "test5"})
            ]
            
            # Add documents to database
            vector_db.add_documents(test_documents)
            print(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(test_documents)} ÙˆØ«ÙŠÙ‚Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            # Test search functionality
            search_queries = [
                "Python programming",
                "web development",
                "machine learning",
                "Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©",
                "ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨"
            ]
            
            for query in search_queries:
                try:
                    results = vector_db.similarity_search(query, k=2)
                    print(f"âœ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{query}': ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ù†ØªÙŠØ¬Ø©")
                    for i, doc in enumerate(results, 1):
                        print(f"   {i}. {doc.page_content[:50]}...")
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{query}': {str(e)[:50]}")
            
            # Test database count
            try:
                count = vector_db._collection.count()
                print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {count}")
            except Exception as e:
                print(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: {str(e)[:50]}")
            
            return True
            
        finally:
            # Clean up temporary directory
            shutil.rmtree(temp_dir)
            print("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return False

def test_text_processing():
    """Test text processing and chunking"""
    print("\nğŸ“ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ...")
    
    try:
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_community.document_loaders import TextLoader
        
        # Create a temporary test file
        test_content = """
        Python Ù‡ÙŠ Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ÙˆÙ…ÙØ³Ø±Ø©.
        ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Guido van Rossum ÙÙŠ Ø¹Ø§Ù… 1991.
        ØªØªÙ…ÙŠØ² Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„Ù‚Ø±Ø§Ø¡Ø©.
        Python ØªØ¯Ø¹Ù… Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ÙƒØ§Ø¦Ù†ÙŠØ©.
        ØªØ³ØªØ®Ø¯Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
        """
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            f.write(test_content)
            temp_file = f.name
        
        try:
            # Test text loading
            loader = TextLoader(temp_file, encoding='utf-8')
            documents = loader.load()
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(documents)} ÙˆØ«ÙŠÙ‚Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù")
            
            # Test text splitting
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=100,
                chunk_overlap=20,
                length_function=len,
                separators=["\n\n", "\n", " ", ""]
            )
            
            chunked_documents = text_splitter.split_documents(documents)
            print(f"âœ… ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {len(chunked_documents)} Ø¬Ø²Ø¡")
            
            for i, chunk in enumerate(chunked_documents, 1):
                print(f"   Ø¬Ø²Ø¡ {i}: {chunk.page_content[:50]}...")
            
            return True
            
        finally:
            # Clean up temporary file
            os.unlink(temp_file)
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ: {e}")
        return False

def test_database_integration():
    """Test full database integration"""
    print("\nğŸ”— Ø§Ø®ØªØ¨Ø§Ø± ØªÙƒØ§Ù…Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    try:
        from langchain_ollama import OllamaEmbeddings
        from langchain_chroma import Chroma
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_core.documents import Document
        
        # Create temporary directory
        temp_dir = tempfile.mkdtemp()
        
        try:
            # Initialize components
            embeddings = OllamaEmbeddings(model="nomic-embed-text")
            vector_db = Chroma(
                persist_directory=temp_dir,
                embedding_function=embeddings
            )
            
            # Create test content
            test_content = """
            Python Programming Guide
            
            Python is a high-level programming language.
            It was created by Guido van Rossum in 1991.
            Python is known for its simplicity and readability.
            
            Key Features:
            - Easy to learn and use
            - Extensive library support
            - Cross-platform compatibility
            - Object-oriented programming support
            
            Common Use Cases:
            - Web development
            - Data analysis
            - Machine learning
            - Automation scripts
            """
            
            # Process text
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=150,
                chunk_overlap=30,
                length_function=len
            )
            
            documents = [Document(page_content=test_content, metadata={"source": "python_guide"})]
            chunked_docs = text_splitter.split_documents(documents)
            
            # Add to database
            vector_db.add_documents(chunked_docs)
            print(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(chunked_docs)} Ø¬Ø²Ø¡ Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            # Test various searches
            search_tests = [
                ("Python features", "features"),
                ("programming language", "language"),
                ("web development", "web"),
                ("machine learning", "learning")
            ]
            
            for query, description in search_tests:
                try:
                    results = vector_db.similarity_search(query, k=1)
                    if results:
                        print(f"âœ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{description}': Ù†Ø¬Ø­")
                    else:
                        print(f"âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{description}': Ù„Ù… ÙŠØ¹ÙŠØ¯ Ù†ØªØ§Ø¦Ø¬")
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{description}': {str(e)[:50]}")
            
            return True
            
        finally:
            shutil.rmtree(temp_dir)
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„: {e}")
        return False

def main():
    """Run all database tests"""
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©...")
    
    tests = [
        ("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†", test_embeddings),
        ("Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©", test_vector_database),
        ("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ", test_text_processing),
        ("ØªÙƒØ§Ù…Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", test_database_integration)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ {test_name}: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {passed}/{total} Ù†Ø¬Ø­")
    
    if passed == total:
        print("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø¬Ø­Øª!")
        print("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")
    else:
        print("âš ï¸ Ø¨Ø¹Ø¶ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ´Ù„Øª")
        print("ğŸ’¡ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)